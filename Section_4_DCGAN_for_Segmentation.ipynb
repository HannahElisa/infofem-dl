{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Section 4: DCGAN for Segmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtwenzel/image-video-understanding/blob/master/Section_4_DCGAN_for_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_jQ1tEQCxwRx"
      },
      "source": [
        "##### Copyright 2020 Fraunhofer MEVIS, 2019 The Tensorflow Authors.\n",
        "Based on a notebook of TensorFlow, available at https://www.tensorflow.org/tutorials/generative/dcgan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "V_sgB_5dx1f1",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQKipAwZ6k51",
        "colab_type": "text"
      },
      "source": [
        "# DC-GAN and WGAN for Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHWV9atHaYn0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy2CDkkH65d1",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation (the well-known CTs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnx99Lrb6kKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash \n",
        "test -e tmp_slices.npz || curl -L \"https://drive.google.com/uc?export=download&id=1R2-H0dhhrj6XNK7Q-MazIWGeFDOf6Zya\" --output tmp_slices.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJIWAWVO69-m",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "TRAINING_SLICE_COUNT = 1600 #@param {min:100, max:3300, step:100}\n",
        "EPOCHS = 50 #@param {min:1, max:200, step:1}\n",
        "\n",
        "loaded = np.load('tmp_slices.npz')\n",
        "\n",
        "x_train = loaded['x_train'][:TRAINING_SLICE_COUNT]\n",
        "y_train = loaded['y_train'][:TRAINING_SLICE_COUNT]\n",
        "\n",
        "x_test = loaded['x_train'][TRAINING_SLICE_COUNT:]\n",
        "y_test = loaded['y_train'][TRAINING_SLICE_COUNT:]\n",
        "\n",
        "assert len(x_train) == len(y_train)\n",
        "print(\"Found %d training and %d testing slices with shape %s\" % (len(x_train),len(x_test), x_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYvfFhk67i4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the lesion labels (values 2..3)\n",
        "y_train_binary = y_train.clip(0, 1)\n",
        "y_test_binary = y_test.clip(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57FUzSsY_iyN",
        "colab_type": "text"
      },
      "source": [
        "## Wrap data\n",
        "We wrap the raw numpy array into a `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE__pQNU8JKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = TRAINING_SLICE_COUNT \n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset_liver = tf.data.Dataset.from_tensor_slices( # A tuple of X and Y to shuffle and batch together.\n",
        "    (np.lib.pad(x_train[...,np.newaxis], [(0,0), (20,20), (20,20), (0,0)], 'reflect'), \n",
        "    y_train_binary[...,np.newaxis]))\\\n",
        "    .shuffle(BUFFER_SIZE)\\\n",
        "    .batch(BATCH_SIZE)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1I_D1RVGjDI",
        "colab_type": "text"
      },
      "source": [
        "## Define new generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeOp-tRG7tbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model_seg(_filters=32, filters_add=0, _kernel_size=(3,3), _padding='same', _activation='relu', _kernel_regularizer=None, _final_layer_nonlinearity='sigmoid'):\n",
        "    model = tf.keras.Sequential()\n",
        "    # We are indifferent about the xy size, but accept only one channel (gray value images). This has the consequence that debugging sizes gets harder.\n",
        "    model.add(layers.InputLayer(input_shape=(116,116,1))) \n",
        "    \n",
        "    model.add(layers.Conv2D(filters=_filters, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer, name='firstConvolutionalLayer'))\n",
        "    model.add(layers.Conv2D(filters=_filters, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.MaxPool2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=_filters+filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.Conv2D(filters=_filters+filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.MaxPool2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=_filters+2*filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.Conv2D(filters=_filters+2*filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.UpSampling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=_filters+filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.Conv2D(filters=_filters+filters_add, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.UpSampling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=_filters, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "    model.add(layers.Conv2D(filters=_filters, kernel_size=_kernel_size, padding=_padding, activation=_activation, kernel_regularizer=_kernel_regularizer))\n",
        "\n",
        "    model.add(layers.Conv2D(1, kernel_size=(1,1), activation=_final_layer_nonlinearity))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNJ0KeQ0GfVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model_seg():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='valid',\n",
        "                                     input_shape=[76, 76, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='valid'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJT-jh43GgBn",
        "colab_type": "text"
      },
      "source": [
        "## Create the full GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaOIWBlYGUas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model_seg(_padding = 'valid')\n",
        "discriminator = make_discriminator_model_seg()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5c1Ui5-HiZZ",
        "colab_type": "text"
      },
      "source": [
        "You may try the `binary_crossentropy` discriminator loss as before, or select to use a Wasserstein loss. Note that this requires to ensure Lipschitzness of discriminator. This is handled in the definition of the train steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvATqaosGeWT",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Select Loss { run: \"auto\" }\n",
        "WASSERSTEIN_LOSS = False #@param {type:\"boolean\"}\n",
        "#@markdown You don't need to re-execute the cell after changing your selection, it auto-executes when it has been executed once.\n",
        "\n",
        "if WASSERSTEIN_LOSS:\n",
        "  # Wasserstein loss (may work only when using a gradient penalty term or at least weight clipping)\n",
        "  def discriminator_loss(real_output, fake_output):\n",
        "      real_loss = -tf.reduce_mean(real_output)\n",
        "      fake_loss = tf.reduce_mean(fake_output)\n",
        "      total_loss = real_loss + fake_loss\n",
        "      return total_loss\n",
        "    \n",
        "  def generator_loss(fake_output):\n",
        "      return -tf.reduce_mean(fake_output)\n",
        "\n",
        "else:\n",
        "  # This method returns a helper function to compute cross entropy loss\n",
        "  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "  cross_entropy_prob = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "  # The discriminator puts out a value from [0,1] for the batch of real and fake segmentations. This is as before.\n",
        "  def discriminator_loss(real_output, fake_output):\n",
        "      real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "      total_loss = real_loss + fake_loss\n",
        "      return total_loss, real_loss, fake_loss\n",
        "    \n",
        "  # The loss for the generator still only sees if the discriminator can tell its generations from real input.\n",
        "  def generator_loss(fake_output):\n",
        "      return cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MKahMwJIsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer     = tf.keras.optimizers.Adam(1e-5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZtpl7h7KQtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCTRUtOTU7R",
        "colab_type": "text"
      },
      "source": [
        "Here is a image output function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX1Ta9MoTTRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray') # Remove the scaling/offset\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "# Draw a random sample of images from the test set for testing\n",
        "example_test_slices = np.random.randint(0,len(x_test),16)\n",
        "seed = x_test[example_test_slices]\n",
        "seed = np.lib.pad(seed[...,np.newaxis], [(0,0), (20,20), (20,20), (0,0)], 'reflect')\n",
        "print(seed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvI_83ddyEM7",
        "colab_type": "text"
      },
      "source": [
        "Set up tensorboard, delete old logs, and create summary writers for train and test like shown [here](https://www.tensorflow.org/tensorboard/get_started)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaHCCOt4VrM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfapDcPNYMt_",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw5N9rBnCmyx",
        "colab_type": "text"
      },
      "source": [
        "Formerly, we only wanted to learn images from random number, this time we replace the random input with an image, and the desired output with the segmentation mask.\n",
        "\n",
        "Recipe:\n",
        "1. Replace `noise` with CT image (first index in tuple)\n",
        "1. `generated_images` are the output of the AE\n",
        "1. Submit the correct images/masks to the loss calculation\n",
        "1. Decouple generator and discriminator updates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E37Y7kscCkv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\", speeding it up a lot. It does not work with inline weight clipping, though.\n",
        "\n",
        "# The parameter \"images\" is expected to hold images and masks, therefore only submit the correct index.\n",
        "\n",
        "#@tf.function\n",
        "def train_step_seg(images, epoch, num_gen_updates, wasserstein_loss):\n",
        "\n",
        "    # Train discriminator\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(images[0], training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "      real_output = discriminator(images[1], training=True)\n",
        "      disc_loss, d_loss_real, d_loss_fake = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      # Write losses into tensorboard log\n",
        "      with train_summary_writer.as_default():\n",
        "          tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
        "          tf.summary.scalar('d_loss_real', d_loss_real, step=epoch)\n",
        "          tf.summary.scalar('d_loss_fake', d_loss_fake, step=epoch)\n",
        "\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    \n",
        "    # Gradient penalty or clipping would go here. Below a simple weight clipping. \n",
        "    # Note that @tf.function (compiling) is impossible, if you want to modify weights this way. You would need to make it a tensor operation to compile it into the graph.\n",
        "    if wasserstein_loss:\n",
        "      d_weights = discriminator.get_weights()\n",
        "      clipped_d_weights = [tf.clip_by_value(w, clip_value_min=0., clip_value_max=1.) for w in d_weights]\n",
        "      discriminator.set_weights(clipped_d_weights)\n",
        "        \n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # Train Generator\n",
        "    for gen_train_step in range(num_gen_updates):\n",
        "      with tf.GradientTape() as gen_tape: \n",
        "        generated_images = generator(images[0], training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        # Write losses into tensorboard log\n",
        "        with train_summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_loss', gen_loss, step=num_gen_updates*epoch+gen_train_step)\n",
        "\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "\n",
        "def train_seg(dataset, epochs, num_gen_updates=1, wasserstein_loss=False):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step_seg(image_batch, epoch, num_gen_updates, wasserstein_loss)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAroGEbVysok",
        "colab_type": "text"
      },
      "source": [
        "Set up Tensorboard connection and call inline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qICG_w7GyrJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start inline TB\n",
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvmHLbU3PLPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seg(train_dataset_liver, epochs=25, num_gen_updates=5, wasserstein_loss=WASSERSTEIN_LOSS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U72N_wgUYQsg",
        "colab_type": "text"
      },
      "source": [
        "## Next Steps\n",
        "You may try to make the model train better. \n",
        "\n",
        "1. Adjust the learning rates.\n",
        "1. Train the generator more often than the discriminator.\n",
        "1. Pooling and upsampling are known to hamper performance. \n",
        "   \n",
        "   Replace with strided convolutions, and with Upconvolutions.\n",
        "1. Next, BatchNorm should be employed in the Generator.\n",
        "1. The cross entropy loss is not optimal. \n",
        "\n",
        "  Anything that tells a real divergence/distance would be better, leading to Wasserstein GANs.\n",
        "\n",
        "  This requires ensuring Lipschitz property of the discriminator, e.g. by weight clipping or gradient penalty, and adjusting the loss accordingly. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-3VdF10PPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}